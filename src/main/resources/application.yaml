server:
  port: 8080

langchain4j:
  open-ai:
    chat-model:
      api-key: ${DASH_SCOPE_API_KEY}

      model-name: deepseek-v3
      log-requests: true
      log-responses: true

      base-url: https://dashscope.aliyuncs.com/compatible-mode/v1
      #温度系数，温度系数越高，AI的发散性思维越强
      temperature: 0.9

  ollama:
    chat-model:
      base-url: http://localhost:11434
      model-name: deepseek-r1:1.5b
      log-requests: true
      log-responses: true

  community:
    dashscope:
      chat-model:
        api-key: ${DASH_SCOPE_API_KEY}
        model-name: qwen-max

logging:
  level:
    dev:
      langchain4j: debug
